\section{Ecuaciones lineales: teoremas de existencia y unicidad.}


\begin{ndef}[Ecuación diferencial lineal]
Sea $(\alpha,\beta)\subseteq \R$ un intervalo abierto y sean $A:(\alpha,\beta)\to \M_d(\R)$ y $b:(\alpha,\beta)\to \R^d$ funciones continuas. Entonces una ecuación diferencial lineal es de la forma:

\begin{equation}
x'=A(t)x+b(t) \tag{C} \label{lin:completa}
,\end{equation}

y se dice \emph{completa}, o bien

\begin{equation}
x'=A(t)x \tag{H} \label{lin:homogenea}
,\end{equation}

y en este caso se dice \emph{homogénea}.
\end{ndef}

\begin{nth}[de existencia y unicidad de la solución]
Dados $t_0\in(\alpha,\beta)$ y $x_0 \in \R^d$ y consideramos el \emph{problema de valores iniciales} (PVI):

\begin{equation}
\left\{\begin{array}{rl}
x' &=A(t)x+b(t), \\
x(t_0)&=x_0.
\end{array}\right.
\tag{PVI}\label{lin:PVI}
\end{equation}

Entonces, existe y es única una función $\varphi : (\alpha,\beta)\to\R^d$, con $\varphi \in \C ^ 1(\R)$, que verifica

\[
\varphi'(t) = A(t)\varphi(t) + b(t) \qquad \forall t \in (\alpha,\beta)
\]

y que además cumple $\varphi(t_0)=x_0$, es decir, una única solución de \ref{lin:PVI}.
\end{nth}

Aplicando el teorema al PVI

\[
\begin{cases}
  x' = Ax, \\
  x(t_0) = e_j.
\end{cases}
\tag{PVI$_j$} \label{lin:PVIj}
\]

para cada $j=1,\dots,d$, obtenemos soluciones $\varphi_j$. Sea $x_0\in \R^d$, y consideramos $\varphi = \sum_{j=1}^d \langle x_0,e_j \rangle\varphi_j$.
Es inmediato comprobar que $\varphi$ es solución de \ref{lin:PVI} con $b=0$. Por tanto, hemos probado:

\begin{ncor}
  Las soluciones de \ref{lin:homogenea} son un espacio vectorial de dimensión $d$.
\end{ncor}

Ahora, consideremos $\varphi$ la solución de \ref{lin:PVI}, para $x_0\in\R^d$ arbitrario, es decir, una solución cualquiera de \ref{lin:completa}.
Sean $\varphi_c$ la solución de

\begin{equation}
\left\{\begin{array}{rl}
x' &=A(t)x+b(t), \\
x(t_0)&=x_0',
\end{array}\right.
\end{equation}

con $x_0'\in\R^d$ arbitrario, y $\varphi_h$ la de

\begin{equation}
\left\{\begin{array}{rl}
x' &=A(t)x, \\
x(t_0)&=x_0 - x_0',
\end{array}\right.
\end{equation}

y ahora es rutinario comprobar que $\varphi = \varphi_c + \varphi_h$. Además, para cualquier otra solución $\psi_{h}$ de \ref{lin:homogenea}, $\varphi_c + \psi_h$
es solución de \ref{lin:completa}.
En esta ocasión, hemos probado:

\begin{ncor}
  El conjunto $S_c$ de soluciones de \ref{lin:completa}, dada cualquier solución $\varphi$ de la misma, es el espacio afín

  \[
    S_c = \varphi + S_h,
    \]

    con $S_h$ el conjunto de soluciones de \ref{lin:homogenea}.
\end{ncor}

Otra consecuencia inmediata de la aplicación del teorema a \ref{lin:PVIj} es la siguiente:

\begin{ncor}[Existencia y unicidad de m.f.p.] \label{lin:cormfp}
  Existe una única función de clase 1 $\Phi: (\alpha, \beta) \to \M_d(\R)$ tal que $\Phi' = A\Phi$, y
  además $\Phi(t_0) = I_d$.
\end{ncor}

\subsection{Matriz fundamental principal en un punto}
Dada una EDO lineal y homogénea con coeficientes constantes:

\begin{equation}
\left\{\begin{array}{rl}
x' &=A(t)x, \\
x(t_0)&=x_0,
\end{array}\right.
\tag{PVIH} \label{lin:PVIH}
\end{equation}

La matriz cuya existencia garantiza \ref{lin:cormfp} (la \emph{matriz fundamental principal (m.f.p.) en $t_0$}) viene dada por:

\[ \Phi(t)=e^{A(t-t_0)} \qquad \forall t \in (\alpha,\beta) \]

Ahora nos preguntamos cómo se calcula la m.f.p. cuando la matriz $A$ es constante y diagonalizable (sobre $\mathbb{C}$). En este caso, existen $P, D \in \M_d(\mathbb{C})$ regulares y tales que $D=\diag(\lambda_1, \dots, \lambda_d)$ y $A=P D  P^{-1}$. En cuyo caso, la matriz fundamental principal será:

\[
  e^{At}=P\cdot e^{Dt}\cdot P^{-1}=P \cdot  \begin{pmatrix}e^{\lambda_1 t} & \cdots & 0 \\ \vdots & \ddots & \vdots \\0 & \cdots & e^{\lambda_d t}\end{pmatrix} \cdot P^{-1}.
\]

\begin{nota}
  Recordando la definición de exponencial de una matriz $A$: $e^A = \sum_{k=0}^\infty \frac{1}{k!} A^k$, obtenemos que, para cada matriz regular $P$,

  \[ e^{PAP^{-1}} =  \sum_{k=0}^\infty \frac{1}{k!} (PAP^{-1})^k = \sum_{k=0}^\infty \frac{1}{k!} PA^kP^{-1} = Pe^AP^{-1}. \]
\end{nota}


Cuando $A$ no sea diagonalizable tendremos que utilizar la forma canónica de Jordan. En este caso, existen $P,J\in \M_d(\mathbb{C})$ regulares, y con $J$ diagonal por bloques:

\[
  J = \begin{pmatrix}J_1 & \cdots & 0\\
 \vdots & \ddots & \vdots \\
 0& \cdots & J_r \end{pmatrix},
 \quad
 e^J = \begin{pmatrix}e^{J_1} & \cdots & 0\\
 \vdots & \ddots & \vdots \\
 0& \cdots & e^{J_r} \end{pmatrix}
\]

 donde, si el orden de $J_k$ es 1, entonces $J_k=(\lambda_k)$ con $\lambda_k$ valor propio de $A$, y en otro caso, si lo llamamos $r$:
 
 \[J_k=
 \begin{pmatrix}
 \lambda_k & 1  & \cdots & 0 \\
  0        & \lambda_k & \ddots & \vdots \\
  \vdots   & \ddots & \ddots & 1 \\
  0        & \cdots & 0 & \lambda_k
 \end{pmatrix},
 \quad
 e^{J_k} = e^{\lambda_k t}\begin{pmatrix}
 1       & t & \cdots & t^r/r! \\
  0      & 1 & \ddots & \vdots \\
  \vdots & \ddots & \ddots & t \\
  0      & \cdots & 0 & 1
 \end{pmatrix}.
 \]

%% FIXME: insertar (aquí o en la sección de ejercicios y referenciado aquí) ejemplos de cálculo de la matriz fundamental.

\section{Estabilidad en el sentido de Lyapunov.}

En esta sección, con arreglo a definir los conceptos básicos de la teoría de estabilidad
de Lyapunov, consideramos un problema de valores iniciales más general:

\begin{equation}
\left\{\begin{array}{rl}
x' &=f(t,x), \\
x(t_0)&=x_0,
\end{array}\right.
\tag{P} \label{est:PVI}
\end{equation}

con $D \subseteq \R \times \R^d$, $f: D \to \R^d$ continua y tal que haya unicidad de soluciones en \ref{est:PVI}.
Notamos, para cada $x_0\in \R^d$ tal que $(t_0,x_0) \in D$, $\varphi_{x_0} : (\alpha, +\infty) \to \R^d$ a la solución maximal de \ref{est:PVI}.

\begin{ndef}
  $\varphi_{x_0}$ es \emph{estable} si, para cada $\varepsilon > 0$, existe $\delta > 0$ tal que

  \[
    (t_0, \bar{x_0}) \in D \text{ y } \|x_0 - \bar{x_0}\| < \delta \implies
  \begin{cases}
    \text{ $\varphi_{\bar{x_0}}$ está definida en $(t_0, +\infty)$}, \\
    \|\varphi_{x_0}(t) - \varphi_{\bar{x_0}}(t)\| < \varepsilon \text{ para cada $t \ge t_0$}.
  \end{cases}
  \]

  $\varphi_{x_0}[t_0, +\infty)+(-\varepsilon, \varepsilon)$ se llama \emph{entorno tubular} de $\varphi_{x_0}$.
\end{ndef}

\begin{ndef}
  Una solución se dice \emph{inestable} si no es estable.
\end{ndef}

%%% TODO: poner algunos ejemplos de PVI con soluciones estables e inestables.

Negando la definición de estabilidad, obtenemos:

\begin{nprop}[Caracterización de soluciones inestables]
  $\varphi_{x_0}$ es inestable si, y solo si, existen $\varepsilon_0 > 0, \xn \subseteq\R^d$ con
  $(t_0,x_n)\in D$, $x_n \to x_0$ y existe, para cada $n\in\N$, $t_n \ge t_0$ tal que

  \[
    \| \varphi_{x_n}(t_n) - \varphi_{x_0}(t_n) \| \ge \varepsilon_0
  .\]
\end{nprop}

\begin{ndef}[Atractor]
  $\varphi_{x_0}$ es un \emph{atractor} (local) si existe $\mu > 0$ tal que, si $(t_0, \bar{x_0})\in D$
  y $\| x_0 - \bar{x_0} \| < \mu$, entonces $\varphi_{\bar{x_0}}$ está definida en $(t_0, +\infty)$ y

  \[
     \lim_{t\to+\infty} \| \varphi_{\bar{x_0}}(t) - \varphi_{x_0}(t) \| = 0.
  \]
\end{ndef}

\begin{ndef}[Estabilidad asintótica]
 $\varphi_{x_0}$ es \emph{asintóticamente estable (a.e.)} si es estable y atractor.
\end{ndef}


%% CLASE LUNES 17

\subsection{Estabilidad en EDO lineales.}

\begin{nprop}
  Las siguientes afirmaciones son equivalentes:

  \begin{nlist}
  \item Todas las soluciones de \ref{lin:completa} son estables, 
  \item existe una solución de \ref{lin:completa} que es estable,
  \item la solución trivial ($\varphi = 0$) de \ref{lin:homogenea} es estable,
  \item todas las soluciones de \ref{lin:homogenea} son acotadas en $[t_0, +\infty)$,
  \item la m.f.p. en $t_0$ de \ref{lin:homogenea} es acotada en $[t_0, +\infty)$.
  \end{nlist}
\end{nprop}

\begin{proof}\hfill\\
  
  \implication{i)}{ii)} Evidente.
  
  \implication{ii)}{iii)} Sean $\varepsilon > 0$, $\esol{x_0}$ solución estable de \ref{lin:completa},
  y $\delta$ el dado por la estabilidad de $\esol{x_0}$ para $\varepsilon$.
    
  Sea $\psi$ solución de \ref{lin:homogenea} con $\| \psi(t_0) \| < \delta$. Entonces, $y := \psi + \esol{x_0}$ es solución de \ref{lin:completa} y
  $\| y(t_0) - \esol{x_0}(t_0) \| = \| \psi(t_0) \| < \delta $, y por la estabilidad, $\| \psi(t) \| < \varepsilon$ para cada $t \in [t_0, +\infty)$.
    
  \implication{iii)}{iv)} Sea $\esol{x_0}$ una solución cualquiera de \ref{lin:homogenea}, y sea $\lambda \in \R^+$ tal que $\| \lambda x_0 \| < \delta$, con $\delta$
    el dado por la estabilidad para $\varepsilon = 1$. Entonces, como $\lambda\esol{x_0}$ es solución, $\| \esol{x_0}(t) \| < 1 / \lambda$ para cada $t \in [t_0, +\infty)$.

  \implication{iv)}{v)} Se deduce usando la norma del supremo tanto en $\R^d$ como en $\M_d(\R)$, y teniendo en cuenta que la m.f.p. está formada por soluciones por columnas. En general,
  basta usar cualquier par de normas tales que la matricial sea compatible con la que se usa en $\R^d$, en el sentido de que $\| Av \| \le \| A \| \|v\|$.

  \implication{v)}{i)} Sean $M$ la cota de la m.f.p., que notamos $\Phi$, y $\varepsilon > 0$.
  Sea $\delta > 0$ tal que $\delta M < \varepsilon$, y $\esol{x_0}, \barsol{x_0}$ soluciones de \ref{lin:completa} tales que $\| x_0 - \bar{x_0} \| < \delta$.
  
  Teniendo en cuenta que $\esol{x_0} = \barsol{x_0} + \Phi(x_0 - \bar{x_0})$, obtenemos $\| \esol{x_0}(t) - \barsol{x_0}(t) \| \le \| \Phi(t) \| \| x_0 - \bar{x_0} \| < M\delta < \varepsilon$.
\end{proof}

\begin{nprop}
Las siguientes afirmaciones son equivalentes:
\begin{nlist}
\item Todas las soluciones de \ref{lin:completa} son atractores.
\item Existe una solución de \ref{lin:completa} que es un atractor.
\item La solución trivial $y = 0$ de \ref{lin:homogenea} es un atractor.
\item Todas las soluciones de \ref{lin:homogenea} convergen hacia el vector 0 cuando $t \to +\infty$.
\item La matriz fundamental de \ref{lin:homogenea} principal en $t_0$ converge hacia la matriz 0 cuando $t \to +\infty$.
\end{nlist}
\end{nprop}

\begin{ncor}
Los atractores de la ecuación \ref{lin:homogenea} son asintóticamente estables.
\end{ncor}

\begin{ndef}\hfill\\
\begin{itemize}
\item Se dice que la ecuación \ref{lin:completa} es estable si todas su soluciones son estables
\item Se dice que la ecuación \ref{lin:completa} es asintóticamente estable si todas sus soluciones son asintóticamente estables.
\end{itemize}
\end{ndef}

No siempre podemos calcular la matriz fundamental, pero nosotros nos centraremos en el caso escalar donde sí podemos calcularla.

\subsubsection{Estabilidad de ecuaciones lineales escalares}
Sean $a,b:(\alpha,+\infty)\to \R$ continuas. Se considera la ecuación diferencial lineal escalar \ref{lin:completa} y sea $t_0\in(\alpha,+\infty)$.
La matriz fundamental principal en $t_0$ en $\phi(t)=exp(\int^t_{t_0} a(s)ds)$ y por tanto podemos caracterizar la estabilidad de \ref{lin:completa} controlando una primitiva del coeficiente $a(t)$.
\begin{nprop}
\begin{itemize}
\item La ecuación de \ref{lin:completa} es estable sii la función $a(t)$ tiene una primitiva acotada superiormente en $[t_0,+\infty]$.
\item La ecuación \ref{lin:completa} es a.e. sii la función $a(t)$ tiene una primitiva que converge hacia $-\infty$ [....]
\end{itemize}
\end{nprop}
Ejemplo 1:
- Inestable
- A.E.
- estable
-
- Inestable
- estable
- estable
-


Estable $-> \lambda <= 0$
A.E. $-> \lambda < 0$
Inestable $-> \lambda > 0$

\subsubsection{Estabilidad de ecuaciones lineales con coeficientes constantes.}
Sea $A \in \M_d(\R)$ una matriz cuadrada.  Usaremos la siguiente notación:
NOTACIÓN:
\begin{ndef}[Espectro de $A$]
El espectro de $A$ es el conjunto de valores propios de $A$, tanto reales como complejos, $\sigma(A)={\lambda_1,...,\lambda_d}$, contados con su multiplicidad en nuestro caso.
\end{ndef}
\begin{ndef}[Multiplicidad del valor propio $\lambda_j$]
$m(\lambda_j) \forall \lambda_j \in \sigma{A}$
\end{ndef}
\begin{ndef}[Dimensión de cada subespacio propio $E_{\lambda_j}$]
$dim E_{\lambda_j} = dim ker(A-\lambda_{jI})= d-rango(A-\lambda I)$
\end{ndef}
\begin{ndef}
Los valores propios de A cuya parte real es 0 son:
$\sigma_0(A)={\lambda \in \sigma(A) \ Re(\lambda)=0}$
\end{ndef}

Consideramos la EDO lineal homogénea y autónoma $x'=Ax x\in\R^d$. El principal indicador para determinar la estabilidad de * es el máximo de las partes reales de los valores propios de A:
$\mu(A)=\max{Re(\lambda : \lambda\in\sigma(A))}$

\begin{nth}
\begin{enumerate}
\item Si $\mu(A)<0$ entonces la EDO lineal * es A.E.
\item Si $\mu(A)=0$ y $m(\lambda)=dimE_\lambda \forall \lambda \in \sigma_0(A)$, entonces la EDO lineal * es estable (pero no A.E.)
\item Si $\mu(A)=0$ y $\exists \lambda \in \sigma_0(A)$ tal que $m(\lambda) != dim E_lambda$, entonces la EDO lineal * es inestable.
\item Si $\mu(A)>0$ entonces la EDO lineal * es inestable.
\end{enumerate}
\end{nth}

A continuación, haremos una serie de ejemplos y proseguiremos con un poquito de teoría para poder producir la demostración de este enunciado.\\
\begin{ejemplo}
\begin{equation}
\left\{\begin{array}{lcl}
x_1'=2x_1+3x_2\\
x_2'=5x_1-x_2
\end{array}\right.
\end{equation}

\begin{equation}
\begin{pmatrix}
x_1 \\
x_2
\end{pmatrix}'=
\begin{pmatrix}
-2 & 3\\
5 & -1
\end{pmatrix}
\begin{pmatrix}
x_1 \\
x_2
\end{pmatrix}
\end{equation}


EC. $\lambda^2-traza(A)\lambda + det(A=0)$
$\lambda+3\lambda-13=0$
$\sigma(A)={\frac{-3+\sqrt{61}}{2},\frac{-3-\sqrt{61}}{2}}={2.4...,5.4...}$
$\mu(A)>2.4 >0$
La ecuación es inestable.
\end{ejemplo}

%% MARTES 18

Recordemos la forma canónica de Jordan.

Sea $A \in \M_d(\R) \exists P, J \in \M_d(\C) tales que:$
\begin{itemize}
\item $P$ es regular (invertible)
\item $J$ es diagonal por bloques:
\begin{equation}
J=diag(J_1,...,J_k) J_j matriz diagonal \forall j=1,...,k
\end{equation}
\item $A=P\cdot J\cdot P^{-1}$
Para calcular $J$ se usan:
\item $\sigma(A)={\lambda_1,...\lambda_d}$
\item $m(\lambda_j)$
\item $dim E_{\lambda_j}$
\item $\nu(\lambda_j)=min{k\in\mathbb{Z}^+: BORRA}$
Los bloques de $J$ pueden ser:
\item de orden 1: $J_k=(\lambda_k) \lambda_k \in \sigma(A)$
\item de orden mayor que 1: $J_k=diag(\lambda_k,...\lambda_k) (1...1 encima de la diag) con \lambda_k \in \sigma(A)$
\item el orden $(J_k) \leq \nu(\lambda_k)$
\item la suma de los órdenes de todos los bloques asociados aun mismo valor propio es igual a la multiplicidad de ese valor propio
\end{itemize}

INSERTE EJEMPLO DE CAJA DE JORDAN

Con estos datos, podemos hacer el siguiente cálculo de la exponencial:

$$A=P\cdot J \cdot P^{-1} \implies A^n=P \cdot J^n \cdot P^{-1} \implies e^A=P \cdot e^J \cdot P^{-1}$$

Y de manera análoga:
\begin{itemize}
\item $e^{At}=P \cdot e^{Jt} \cdot P^{-1}$
\item $e^{Jt}=diag(e^{J_1t},...,e^{J_rt} )$
\end{itemize}

%% Inserte ejemplo

\begin{lema}
$$|||e^{Jt}|||_1=\max{|||e^{J_1t}|||_1,|||e^J_rt|||_1}$$
\end{lema}

\begin{lema}
$\exists T \geq 0 $ tal que :
$$|||e^{Jt}|||_1=\left(1+...+\frac{t^n}{n!}\right)\cdot e^{\mu t} \qquad \forall t \geq T$$
donde:
$$\mu=\max{Re(\lambda_j):\lambda_j\in \sigma(A)}$$
$$n=\max{\nu(\lambda_j)-1 : \lambda_j\in \sigma(A) y Re(\lambda_j)=\mu}$$
\end{lema}

Usando el lema anterior:
\begin{equation}
|||e^{Jt}|||_1=\max
\left\{ {\left(
1+...+\frac{t^{\nu(\lambda_j)-1}}{(\nu (\lambda_j)-1)!}
\right) }
\cdot e^{Re(\lambda_j)t} : \lambda_j \in \sigma(A) \right\}
\tag{cosarara}\label{cosarara}
\end{equation}
$\exists T \geq 0$ tal que:
\begin{equation}
(1+...+\frac{t^{\nu(\lambda_j)-1}}{\nu(\lambda_j - 1})\cdot e^{Re(\lambda_j)t} \leq (1+...1+\frac{t^n}{n!}e^{\mu t})
\end{equation}

Finalmente, podemos demostrar el teorema anterior:

\begin{proof}
$\exists P, J \in \M_d(\C)$ tales que $P$ es inestable, $J$ es diagonal por bloques y $A=P\cdot J \cdot P^{-1}$. Por tanto $$e^{At}=P\cdot e^{Jt} \cdot P^{-1}$$.
Defino en $\M_d(\C)$ la norma matricial:
$$|||B|||=|||P\cdot J \cdot P^{-1}|||_1$$.
Así, tenemos que:
\begin{enumerate}
\item Si $\mu < 0 \implies \lim_{t\to\infty}|||e^{At}|||=0\implies x'=Ax$ es A.E.
\item Si $\mu = 0 y dimE_j=m(\lambda)' \forall \lambda \in \sigma_0(A)\implies n=0 \implies |||e^{At}|||=1\implies|||e^{At}||| es estable pero no A.E.$
\item Si $\mu = 0 y \exists \lambda \in \sigma_0(A) \nu(A)>1 \implies n\geq 1\implies |||e^{At}|||\geq 1+t$ no es acotada en $[0,+\infty)$
\item Si $\mu > 0 \qquad |||e^{At}|||\geq e^{\mu t}\to \infty$ no es acotada en $[0,+\infty)$
\end{enumerate}
\end{proof}


%% MIÉRCOLES 19
\section{Órbitas}
%% Lunes 24
\subsection{Diagramas de fase planos de EDO lineales}

Consideramos la EDO lineal homogénea autónoma en $\R^2$:

\begin{equation}
\left\{\begin{array}{rl}
x_1'=a_{11}x_1+a_{12}x_2 \\
x_2'=a_{21}x_1+a_{22}x_2
\end{array}\right.\Leftrightarrow
\begin{pmatrix}
x_1 \\
x_2 \\
\end{pmatrix}
'=
\begin{pmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22} \\
\end{pmatrix}
\begin{pmatrix}
x_1 \\
x_2 \\
\end{pmatrix}
\end{equation}

%%%%%%%% Definiciones para los diagramas de fase. http://www.texample.net/tikz/examples/poincare/

\newcommand\newtemplate[4][0.4]%
 {\newsavebox#2%
   \savebox#2%
   {\begin{tabular}{@{}c@{}}
      \\[2#1ex]
      \begin{tikzpicture}[scale=#1]
      #4
      \end{tikzpicture}\\[4#1ex]
      %% \templatecaption{#3}\\[-1ex]
     \end{tabular}%
   }%
 }
\newcommand\template[1]{\usebox{#1}}             % use the Code stored in box #1
\newcommand\templatecaption[1]{{\sffamily\scriptsize#1}}       % typeset caption
\newcommand\Tr{\mathop{\mathrm{tr}}}

\newtemplate\sink{sink}%
 {\foreach \sx in {+,-}                   % for right/left half do:
   {\draw[flow] (\sx4,0) -- (0,0);        %   draw half of horizontal axis
    \draw[flow] (0,\sx4) -- (0,0);        %   draw half of vertical axis
    \foreach \sy in {+,-}                 %   for upper/lower quadrant do:
      \foreach \a/\b in {2/1,3/0.44}      %     draw two half-parabolas
        \draw[flow,domain=\sx\a:0] plot (\x, {\sy\b*\x*\x});
   }
 }

\newtemplate\source{source}%
 {\foreach \sx in {+,-}                   % for right/left half do:
   {\draw[flow] (0,0) -- (\sx4,0);        %   draw half of horizontal axis
    \draw[flow] (0,0) -- (0,\sx4);        %   draw half of vertical axis
    \foreach \sy in {+,-}                 %   for upper/lower quadrant do:
      \foreach \a/\b in {2/1,3/0.44}      %     draw two half-parabolas
        \draw[flow,domain=0:\sx\a] plot (\x, {\sy\b*\x*\x});
   }
 }

\newtemplate\stablefp{line of stable fixed points}%
 {\draw (-4,0) -- (4,0);                  % draw horizontal axis
  \foreach \sy in {+,-}                   % for upper/lower half do:
   {\draw[flow] (0,\sy4) -- (0,0);        %   draw half of vertical axis
    \foreach \x in {-3,-2,-1,1,2,3}       %   draw six vertical half-lines
      \draw[flow] (\x,\sy3) -- (\x,0);
   }
 }

\newtemplate\unstablefp{line of unstable fixed points}%
 {\draw (-4,0) -- (4,0);                  % draw horizontal axis
  \foreach \sy in {+,-}                   % for upper/lower half do:
   {\draw[flow] (0,0) -- (0,\sy4);        %   draw half of vertical axis
    \foreach \x in {-3,-2,-1,1,2,3}       %   draw six vertical half-lines
      \draw[flow] (\x,0) -- (\x,\sy3);
   }
 }

\newtemplate\spiralsink{spiral sink}%
 {\draw (-4,0) -- (4,0);                  % draw horizontal axis
  \draw (0,-4) -- (0,4);                  % draw vertical axis
  \draw [samples=100,smooth,domain=27:7]  % draw spiral
       plot ({\x r}:{0.005*\x*\x});       % Using "flow" here gives "Dimension
  \def\x{26}                              %        too large", so we draw a tiny
  \draw[->] ({\x r}:{0.005*\x*\x}) -- +(0.01,-0.01);%     tangent for the arrow.
 }

\newtemplate\spiralsource{spiral source}%
 {\draw (-4,0) -- (4,0);                  % draw horizontal axis
  \draw (0,-4) -- (0,4);                  % draw vertical axis
  \draw [samples=100,smooth,domain=10:28] % draw spiral
       plot ({-\x r}:{0.005*\x*\x});      % Using "flow" here gives "Dimension
  \def\x{27.5}                            %        too large", so we draw a tiny
  \draw[<-] ({-\x r}:{0.005*\x*\x}) -- +(0.01,-0.008);%   tangent for the arrow.
 }

\newtemplate[0.15]\centre{center}% British spelling since \center is in use
 {\draw (-4,0) -- (4,0);                  % draw horizontal axis
  \draw (0,-4) -- (0,4);                  % draw vertical axis
  \foreach \r in {1,2,3}                  % draw three circles
    \draw[flow=0.63] (\r,0) arc (0:-360:\r cm);
 }

\newtemplate\saddle{saddle}%
 {\foreach \sx in {+,-}                   % for right/left half do:
   {\draw[flow] (\sx4,0) -- (0,0);        %   draw half of horizontal axis
    \draw[flow] (0,0) -- (0,\sx4);        %   draw half of vertical axis
    \foreach \sy in {+,-}                 %   for upper/lower quadrant do:
      \foreach \a/\b/\c/\d in {2.8/0.3/0.7/0.6, 3.9/0.4/1.3/1.1}
        \draw[flow] (\sx\a,\sy\b)         %     draw two bent lines
          .. controls (\sx\c,\sy\d) and (\sx\d,\sy\c)
          .. (\sx\b,\sy\a);
   }
 }

\newtemplate\degensink{degenerate sink}%
 {\draw (0,-4) -- (0,4);                  % draw vertical axis
  \foreach \s in {+,-}                    % for upper/lower half do:
   {\draw[flow] (\s4,0) -- (0,0);         %   draw half of horizontal axis
    \foreach \a/\b/\c/\d in {3.5/4/1.5/1, 2.5/2/1/0.8}
      \draw[flow] (\s-3.5,\s\a)           %   draw two bent lines
        .. controls (\s\b,\s\c) and (\s\b,\s\d)
        .. (0,0);
   }
 }

\newtemplate\degensource{degenerate source}%
 {\draw (0,-4) -- (0,4);                  % draw vertical axis
  \foreach \s in {+,-}                    % for upper/lower half do:
   {\draw[flow] (0,0) -- (\s4,0);         %   draw half of horizontal axis
    \foreach \a/\b/\c/\d in {3.5/4/1.5/1, 2.5/2/1/0.8}
      \draw[flow] (0,0)                   %   draw two bent lines
        .. controls (\s\b,\s\d) and (\s\b,\s\c)
        .. (\s-3.5,\s\a);
   }
 }


%%%%%%%%


\subsubsection{Valores propios reales}

Consideramos primero el caso en que $\sigma(A)={\lambda_1,\lambda_2}\subset \R$, y a su vez analizamos el resto de casos según los signos
de los valores propios.

\paragraph{Reales, positivos y distintos:} $0<\lambda_1<\lambda_2$
$\Leftrightarrow \left\{ \begin{array}{ll}\Delta > 0, \\ \tr(A)>0, \\ \det(A) > 0. \end{array}\right.$

%%% FIXME: poner el texto y la figura en dos columnas con multicol

  \begin{figure}[h]
    \centering
    \begin{tikzpicture}[line cap=round,line join=round, scale=0.5]
   \foreach \sx in {+,-}                   % for right/left half do:
   {\draw[flow] (0,0) -- (\sx4,0);        %   draw half of horizontal axis
    \draw[flow] (0,0) -- (0,\sx4);        %   draw half of vertical axis
    \foreach \sy in {+,-}                 %   for upper/lower quadrant do:
      \foreach \a/\b in {2/1,3/0.44}      %     draw two half-parabolas
        \draw[flow,domain=0:\sx\a] plot (\x, {\sy\b*\x*\x});
        }
    \end{tikzpicture}
    \caption{Una fuente.}

  \end{figure}

$x(t)=c_1 e^{\lambda_1t}v_1+c_2 e^{\lambda_2t}v_2 \qquad v_j \in E_{\lambda_j}$

\begin{nlist}
  
\item Sonreales, negativos y distintos: $\lambda_2 < \lambda_1 \Leftrightarrow \left\{ \begin{array}{ll}\Delta > 0 \\ \tr(A) < 0 \\ \det(A)>0\end{array}\right.$
Inserte dibujito de sumidero (flechas hacia dentro)
\item Son reales, no nulos y con distinto signo : $\lambda_1 < 0 < \lambda_2 \Leftrightarrow \det(A)<0$
Inserte dibujito de punto hiperbólico o punto silla
\item Son reales, positivos e iguales : $\lambda_1=\lambda_2>0 \Leftrightarrow \left\{ \begin{array}{ll} \Delta = 0 \\ \tr(A)>0\end{array}\right.$.
  
\begin{enumerate}
\item Si $A$ es diagonalizable : En este caso tendremos todo el espacio y volveremos a tener una fuente.
\item Si $A$ no es diagonalizable : Nos encontramos con una fuente degenerada.
\end{enumerate}

\item Son reales, negativos e iguales : $\lambda_1=\lambda_2<0 \Leftrightarrow \left\{ \begin{array}{ll} \Delta = 0 \\ \tr(A)<0\end{array}\right.$.
  
\begin{enumerate}
\item Si $A$ es diagonalizable : En este caso tendremos todo el espacio y volveremos a tener un sumidero.
\item Si $A$ no es diagonalizable : Nos encontramos con un sumidero degenerado.
\end{enumerate}

\item Un valor propio es 0 y el otro positivo: $\lambda>0$ \\
Inserte dibujito rectas paralelas y perpendiculares a una única recta generada por el 0(Hacia dentro). Rectas  de puntos de equilibrio estables
\item Un valor propio es 0 y el otro negativo: $\lambda<0 $ \\
Inserte dibujito rectas paralelas y perpendiculares a una única recta generada por el 0(Hacia fuera). Rectas  de puntos de equilibrio inestables
\item Dos valores propios iguales a 0: $\lambda_1=\lambda_2=0 \Leftrightarrow \left\{ \begin{array}{ll}\Delta=0 \\ \tr(A)=0 \\ \det(A)=0\end{array}\right.$
  
\begin{enumerate}
\item Si $A$ es diagonalizable $A=0$
\item Si $A$ no es diagonalizable.
\end{enumerate}


\item Caso 2: Cuando los valores propios de la matriz A no son reales : $\sigma(A)={\lambda_1,\lambda_2}\subset \mathbb{C} - \R, \; \lambda_1=a+bi$ y $ \lambda_2=a-bi$.
  
\begin{enumerate}
\item Tiene parte real positiva $\left\{\begin{array}{ll} \Delta < 0 \\ tr(A) > 0 \end{array}\right.$ Fuente en espiral
\item Tiene parte real negativa $\left\{\begin{array}{ll} \Delta < 0 \\ tr(A) < 0 \end{array}\right.$ Sumidero en espiral
\item Tiene parte real igual a 0. Diagrama de Poincaré
\end{enumerate}

\end{nlist}

%% MARTES 25

\begin{ejemplo}
\end{ejemplo}

PREGUNTA EXAMEN PARCIAL: Representar el diagrama de fases

\begin{nota}
Recuerda que si $\lambda \in \sigma(A)$ y $v \in E_\lambda$ tal que $A\cdot v =\lambda\cdot v$ entonces $\varphi(t)=k\cdot e^{\lambda t}\cdot v \quad \forall t \in \R$ es solución de $x'=Ax$ y si $\varphi(t)\in E_\lambda \quad t \in \R \implies E_\lambda$ es invariante. De manera análoga $E_{\lambda_1}\oplus E_{\lambda_2} \quad k_1 e^{\lambda_1 t}v_1+k_2 e^{\lambda_2 t}v_2$ es también invariante.\\
El subespacio propio generalizado sería $\lambda\in\sigma(A) \quad \hat{E}_\lambda = \cup_{k\in\N}Ker(A-\lambda I)^k=Ker(A-\lambda I)^{\nu(\lambda) }$ con $\dim \hat{E}_\lambda=m(\lambda)$.\\
Se puede hacer la siguiente descomposición de $\R^d$.\\
Se definen:
$$E=\bigoplus_{ \begin{array}{c}\lambda\in\sigma(A)\\ Re(\lambda)<0\end{array}}\hat{E}_\lambda$$
$$\mho=\bigoplus_{\begin{array}{c}\lambda\in\sigma(A) \\ Re(\lambda)>0\end{array}}\hat{E}_\lambda$$
$$\mathcal{Z}=\bigoplus_{\begin{array}{c}\lambda\in\sigma_0(A)\end{array}}\hat{E}_\lambda$$
\end{nota}


entonces para $x'=Ax$:

$$\R^d=E\oplus\mathcal{Z}\oplus\mho$$

\begin{ejer}
Estudia la estabilidad del sistema lineal:
\[
\left\{\begin{array}{ll}
x'=-2tx \\
y'=e^tx-2ty
\end{array}\right.
\]
\end{ejer}
\begin{ejer}
Estudia la estabilidad del sistema lineal:
\[
\left\{\begin{array}{ll}
x'=-2x+5y\\
y'=-3x+4y
\end{array}\right.
\]
Comenzamos calculando la traza y el determinante de la matriz $A=\begin{pmatrix}-2 & 5 \\ -3 & 4 \end{pmatrix}$. Tenemos entonces que:
$$tr(A)=2=\lambda_1+\lambda_2=2 Re \lambda_1 >0$$
$$det(A)=7=\lambda_1 \cdot \lambda_2$$
$Re\lambda_1, Re\lambda_2>0$ luego si son reales será inestable y como $2 Re \lambda_1 >0$ entonces si son complejos también será inestable.
\end{ejer}

\begin{ejer}
\[
\left\{\begin{array}{ll}
x'=-2x+y-z\\
y'=2x-3y+z\\
z'=4x-4y+2z
\end{array}\right.
\]

Tras unos cálculos, tenemos que: $\sigma(A)={-2,-1,0}$ luego es estable pero no asintóticamente estable.
\end{ejer}

\begin{nota}
 El polinomio característico de $A\in\M(\mathbb{C})$ es $-\lambda^3+tr(A)\lambda^2-tr(adj(A))\lambda+det(A)$.
\end{nota}

\begin{ejer}
Estudia la estabilidad (FALTA)
\end{ejer}

\begin{ejer}
Representa el diagrama de fases de la EDO lineal:
\[
\left\{\begin{array}{ll}
x'=-x+3y\\
y'=2x-4y
\end{array}\right.
\]
\end{ejer}

\begin{sol}
Sus valores propios son:
$$\lambda_1=\frac{1}{2}(-5-\sqrt{33})\approx -5.37$$
$$\lambda_2=\frac{1}{2}(-5+\sqrt{33})\approx 0.37$$
Y sus vectores propios serían:
$$v_1=\begin{pmatrix}-0.68 \\ 1 \end{pmatrix} $$
$$v_2=\begin{pmatrix}2.19 \\ 1 \end{pmatrix} $$
\end{sol}

%%\includegraphics{streamplotwolframalpha.gif}

\section{Ecuaciones no lineales: generalidades sobre existencia y unicidad de la solución}

\begin{ndef}[Solución de una EDO]
Dados un conjunto abierto $D \subset \R \times \R^d$ y una función continua $f:D\to \R^d$, consideramos la ecuación diferencial ordinaria (EDO):
\begin{equation}
x'=f(t,x) \tag{EDO}\label{nolin:EDO}
\end{equation}
Una \emph{solución} de una \ref{nolin:EDO} en un intervalo abierto $\varphi:J\to\R^d$ que verifica:
\begin{itemize}
\item $\varphi$ continua y derivable en $J$
\item $\varphi'(t)=f(t,\varphi(t)) \quad \forall t \in J$
\end{itemize}
\end{ndef}

\begin{ndef}[Solución Prolongable]
Una solución $\varphi : J \to \R^d$ es \emph{prolongable} si existe otra solución $\hat{\varphi} : \hat{J}\to\R^d$ tal que:
\begin{itemize}
\item $J\subsetneq \hat{J}$.
\item $\hat{\varphi}_{|J} = \varphi$.
\end{itemize}
\end{ndef}

\begin{ndef}[Solución Maximal]
Una solución que no es prolongable recibe el nombre de \emph{maximal}.
\end{ndef}

Dadas dos soluciones de la \ref{nolin:EDO}:
$$\varphi_1:J_1\to \R^d \qquad \varphi_2 : J_2 \to \R^d$$
tales que existe $\tau \in J_1 \bigcap J_2 $ tal que $\varphi_1(\tau)=\varphi_2(\tau)$ y se verifica que la función definida a trozos:
$$
\phi : J_1 \bigcup J_2 \to \R^d, \quad \phi(t)=\left \{ \begin{array}{lcr}
\varphi_1(t) & si & t\leq \tau \\
\varphi_2(t) &  si & t\geq \tau
\end{array}
\right .
$$
también es solución de la \ref{nolin:EDO}.
Dados un conjunto abierto $D \subset \R \times \R^d$, un punto $(t_0,x_0)\in D$ y una función continua $f:D\to\R^d$, consideramos el problema de valores iniciales:
\begin{equation}
\left\{\begin{array}{rl}
x' &=f(t,x), \\
x(t_0)&=x_0.
\end{array}\right.
\tag{PVI}\label{nolin:PVI}
\end{equation}
\begin{ndef}[Solución de un \ref{nolin:PVI}]
Es una función $\varphi : J \to \R^d$ donde:
\begin{enumerate}
\item $J\subset \R$ es un intervalo abierto tal que $t_0\in J$,
\item $\varphi(t_0)=x_0$,
\item $\varphi$ es solución de la EDO $x'=f(t,x)$.
\end{enumerate}
\end{ndef}

Existen varios conceptos de unicidad:

\begin{ndef}[Unicidad Global]
El \ref{nolin:EDO} verifica la propiedad de \emph{unicidad glopal} si para cualquier par de solución del \ref{nolin:PVI}
$$\varphi_1:J\to\R^d \qquad \varphi_2\to\R^d$$
se cumple $\forall t \in J_1 \bigcap J_2$ que $\phi_1(t)=\phi_2(t)$.
\end{ndef}
\begin{ndef}[Unicidad Local]

\end{ndef}

Faltan más conceptos de unicidad.
